{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions utilisés dans le notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alerteCombinaison(dictionary_param):\n",
    "    \"\"\"\n",
    "    Cette fonction est utilisée pour calculer le nombre de combinaison\n",
    "    défini des GridSearch pour optimiser les paramtètres des modèles.\n",
    "    Elle prend en entrée un dictionnaire et retourne le nombre de combinaison\n",
    "    \"\"\"\n",
    "    from numpy import prod\n",
    "    lengths = [len(v) for v in dictionary_param.values()]\n",
    "    count = prod(lengths)\n",
    "    if count < 500:\n",
    "        print(\"C'est bon tu peux envoyer l'apprentissage !\")\n",
    "    elif count < 1000:\n",
    "        print(\"Tu peux lire tes mails pendant l'apprentissage !\")\n",
    "    elif count < 2000:\n",
    "        print(\"Tu peux répondre à tes mails pendant l'apprentissage !\")\n",
    "    else:\n",
    "        print(\"Tu peux mettre ton PC en veille et revenir demain !\")\n",
    "\n",
    "    print(\"Nombre de combinaison :\")\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No disposition</th>\n",
       "      <th>Date mutation</th>\n",
       "      <th>Nature mutation</th>\n",
       "      <th>Valeur fonciere</th>\n",
       "      <th>Type de voie</th>\n",
       "      <th>Voie</th>\n",
       "      <th>Code postal</th>\n",
       "      <th>Commune</th>\n",
       "      <th>Code commune</th>\n",
       "      <th>Section</th>\n",
       "      <th>...</th>\n",
       "      <th>1er lot</th>\n",
       "      <th>Surface Carrez du 1er lot</th>\n",
       "      <th>Nombre de lots</th>\n",
       "      <th>Type local</th>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <th>Nature culture</th>\n",
       "      <th>Surface terrain</th>\n",
       "      <th>col_concat</th>\n",
       "      <th>Moyenne Taux Chomage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>Vente</td>\n",
       "      <td>204332.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>DES ECUREUILS</td>\n",
       "      <td>01</td>\n",
       "      <td>BUELLAS</td>\n",
       "      <td>65</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>S</td>\n",
       "      <td>866.0</td>\n",
       "      <td>04/01/2021ALL7.00276DES ECUREUILS1310.0BUELLAS</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>Vente</td>\n",
       "      <td>226700.0</td>\n",
       "      <td>CHE</td>\n",
       "      <td>DU MOULIN DE POLAIZE</td>\n",
       "      <td>01</td>\n",
       "      <td>POLLIAT</td>\n",
       "      <td>301</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/01/2021CHE173.00164DU MOULIN DE POLAIZE1310...</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>08/01/2021</td>\n",
       "      <td>Vente</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>DES GRANGES BONNET</td>\n",
       "      <td>01</td>\n",
       "      <td>PERONNAS</td>\n",
       "      <td>289</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>S</td>\n",
       "      <td>703.0</td>\n",
       "      <td>08/01/2021RUE46.00161DES GRANGES BONNET1960.0P...</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>Vente</td>\n",
       "      <td>114500.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>DE LA MAIRIE</td>\n",
       "      <td>01</td>\n",
       "      <td>FOISSIAT</td>\n",
       "      <td>163</td>\n",
       "      <td>AB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>S</td>\n",
       "      <td>87.0</td>\n",
       "      <td>07/01/2021RUE179.00110DE LA MAIRIE1340.0FOISSIAT</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>08/01/2021</td>\n",
       "      <td>Vente</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>IMP</td>\n",
       "      <td>DE CHAMANDRE</td>\n",
       "      <td>01</td>\n",
       "      <td>FOISSIAT</td>\n",
       "      <td>163</td>\n",
       "      <td>WC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Maison</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>08/01/2021IMP8.00255DE CHAMANDRE1340.0FOISSIAT</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765379</th>\n",
       "      <td>1</td>\n",
       "      <td>27/12/2018</td>\n",
       "      <td>Vente</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>PL</td>\n",
       "      <td>DES VOSGES</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 04</td>\n",
       "      <td>104</td>\n",
       "      <td>AO</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27/12/2018PL9.09917DES VOSGES75004.0PARIS 04</td>\n",
       "      <td>6.63125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765380</th>\n",
       "      <td>1</td>\n",
       "      <td>28/12/2018</td>\n",
       "      <td>Vente</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>BEAUTREILLIS</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 04</td>\n",
       "      <td>104</td>\n",
       "      <td>AQ</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.87</td>\n",
       "      <td>2</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28/12/2018RUE13.00797BEAUTREILLIS75004.0PARIS 04</td>\n",
       "      <td>6.63125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765381</th>\n",
       "      <td>1</td>\n",
       "      <td>26/12/2018</td>\n",
       "      <td>Vente</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>DES LIONS SAINT PAUL</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 04</td>\n",
       "      <td>104</td>\n",
       "      <td>AQ</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26/12/2018RUE14.05702DES LIONS SAINT PAUL75004...</td>\n",
       "      <td>6.63125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765382</th>\n",
       "      <td>1</td>\n",
       "      <td>03/12/2018</td>\n",
       "      <td>Vente</td>\n",
       "      <td>383000.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>POISSONNIERE</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 02</td>\n",
       "      <td>102</td>\n",
       "      <td>AO</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.78</td>\n",
       "      <td>1</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/12/2018RUE12.07561POISSONNIERE75002.0PARIS 02</td>\n",
       "      <td>6.63125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765383</th>\n",
       "      <td>1</td>\n",
       "      <td>17/10/2018</td>\n",
       "      <td>Vente</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>SAINT-DENIS</td>\n",
       "      <td>75</td>\n",
       "      <td>PARIS 02</td>\n",
       "      <td>102</td>\n",
       "      <td>AP</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17/10/2018RUE273.08525SAINT-DENIS75002.0PARIS 02</td>\n",
       "      <td>6.63125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2765384 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         No disposition Date mutation Nature mutation  Valeur fonciere  \\\n",
       "0                     1    04/01/2021           Vente         204332.0   \n",
       "1                     2    04/01/2021           Vente         226700.0   \n",
       "2                     1    08/01/2021           Vente         185000.0   \n",
       "3                     1    07/01/2021           Vente         114500.0   \n",
       "4                     1    08/01/2021           Vente         145000.0   \n",
       "...                 ...           ...             ...              ...   \n",
       "2765379               1    27/12/2018           Vente           1800.0   \n",
       "2765380               1    28/12/2018           Vente         405000.0   \n",
       "2765381               1    26/12/2018           Vente         220000.0   \n",
       "2765382               1    03/12/2018           Vente         383000.0   \n",
       "2765383               1    17/10/2018           Vente          45000.0   \n",
       "\n",
       "        Type de voie                  Voie Code postal   Commune  \\\n",
       "0                ALL         DES ECUREUILS          01   BUELLAS   \n",
       "1                CHE  DU MOULIN DE POLAIZE          01   POLLIAT   \n",
       "2                RUE    DES GRANGES BONNET          01  PERONNAS   \n",
       "3                RUE          DE LA MAIRIE          01  FOISSIAT   \n",
       "4                IMP          DE CHAMANDRE          01  FOISSIAT   \n",
       "...              ...                   ...         ...       ...   \n",
       "2765379           PL            DES VOSGES          75  PARIS 04   \n",
       "2765380          RUE          BEAUTREILLIS          75  PARIS 04   \n",
       "2765381          RUE  DES LIONS SAINT PAUL          75  PARIS 04   \n",
       "2765382          RUE          POISSONNIERE          75  PARIS 02   \n",
       "2765383          RUE           SAINT-DENIS          75  PARIS 02   \n",
       "\n",
       "         Code commune Section  ...  1er lot Surface Carrez du 1er lot  \\\n",
       "0                  65       B  ...      NaN                       NaN   \n",
       "1                 301      AA  ...      NaN                       NaN   \n",
       "2                 289      AD  ...      NaN                       NaN   \n",
       "3                 163      AB  ...      NaN                       NaN   \n",
       "4                 163      WC  ...      NaN                       NaN   \n",
       "...               ...     ...  ...      ...                       ...   \n",
       "2765379           104      AO  ...    109.0                       NaN   \n",
       "2765380           104      AQ  ...     16.0                     33.87   \n",
       "2765381           104      AQ  ...    126.0                       NaN   \n",
       "2765382           102      AO  ...      9.0                     34.78   \n",
       "2765383           102      AP  ...     57.0                       NaN   \n",
       "\n",
       "         Nombre de lots   Type local Surface reelle bati  \\\n",
       "0                     0       Maison                88.0   \n",
       "1                     0       Maison                96.0   \n",
       "2                     0       Maison               100.0   \n",
       "3                     0       Maison                85.0   \n",
       "4                     0       Maison                92.0   \n",
       "...                 ...          ...                 ...   \n",
       "2765379               1  Appartement                20.0   \n",
       "2765380               2  Appartement                34.0   \n",
       "2765381               2  Appartement                29.0   \n",
       "2765382               1  Appartement                34.0   \n",
       "2765383               1  Appartement                11.0   \n",
       "\n",
       "         Nombre pieces principales  Nature culture Surface terrain  \\\n",
       "0                              4.0               S           866.0   \n",
       "1                              3.0             NaN             NaN   \n",
       "2                              4.0               S           703.0   \n",
       "3                              2.0               S            87.0   \n",
       "4                              1.0               S          2480.0   \n",
       "...                            ...             ...             ...   \n",
       "2765379                        2.0             NaN             NaN   \n",
       "2765380                        1.0             NaN             NaN   \n",
       "2765381                        1.0             NaN             NaN   \n",
       "2765382                        1.0             NaN             NaN   \n",
       "2765383                        1.0             NaN             NaN   \n",
       "\n",
       "                                                col_concat  \\\n",
       "0           04/01/2021ALL7.00276DES ECUREUILS1310.0BUELLAS   \n",
       "1        04/01/2021CHE173.00164DU MOULIN DE POLAIZE1310...   \n",
       "2        08/01/2021RUE46.00161DES GRANGES BONNET1960.0P...   \n",
       "3         07/01/2021RUE179.00110DE LA MAIRIE1340.0FOISSIAT   \n",
       "4           08/01/2021IMP8.00255DE CHAMANDRE1340.0FOISSIAT   \n",
       "...                                                    ...   \n",
       "2765379       27/12/2018PL9.09917DES VOSGES75004.0PARIS 04   \n",
       "2765380   28/12/2018RUE13.00797BEAUTREILLIS75004.0PARIS 04   \n",
       "2765381  26/12/2018RUE14.05702DES LIONS SAINT PAUL75004...   \n",
       "2765382   03/12/2018RUE12.07561POISSONNIERE75002.0PARIS 02   \n",
       "2765383   17/10/2018RUE273.08525SAINT-DENIS75002.0PARIS 02   \n",
       "\n",
       "        Moyenne Taux Chomage  \n",
       "0                    6.10000  \n",
       "1                    6.10000  \n",
       "2                    6.10000  \n",
       "3                    6.10000  \n",
       "4                    6.10000  \n",
       "...                      ...  \n",
       "2765379              6.63125  \n",
       "2765380              6.63125  \n",
       "2765381              6.63125  \n",
       "2765382              6.63125  \n",
       "2765383              6.63125  \n",
       "\n",
       "[2765384 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataframe2.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "\n",
    "# Maintenant, df contient la DataFrame importée depuis le fichier\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echantillonage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <th>Surface terrain</th>\n",
       "      <th>Nombre de lots</th>\n",
       "      <th>Moyenne Taux Chomage</th>\n",
       "      <th>Type local_Appartement</th>\n",
       "      <th>Type local_Dépendance</th>\n",
       "      <th>Type local_Local industriel. commercial ou assimilé</th>\n",
       "      <th>Type local_Maison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765379</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.63125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765380</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6.63125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765381</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6.63125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765382</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.63125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765383</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.63125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2765384 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nombre pieces principales  Surface reelle bati  Surface terrain  \\\n",
       "0                              4.0                 88.0            866.0   \n",
       "1                              3.0                 96.0              NaN   \n",
       "2                              4.0                100.0            703.0   \n",
       "3                              2.0                 85.0             87.0   \n",
       "4                              1.0                 92.0           2480.0   \n",
       "...                            ...                  ...              ...   \n",
       "2765379                        2.0                 20.0              NaN   \n",
       "2765380                        1.0                 34.0              NaN   \n",
       "2765381                        1.0                 29.0              NaN   \n",
       "2765382                        1.0                 34.0              NaN   \n",
       "2765383                        1.0                 11.0              NaN   \n",
       "\n",
       "         Nombre de lots  Moyenne Taux Chomage  Type local_Appartement  \\\n",
       "0                     0               6.10000                   False   \n",
       "1                     0               6.10000                   False   \n",
       "2                     0               6.10000                   False   \n",
       "3                     0               6.10000                   False   \n",
       "4                     0               6.10000                   False   \n",
       "...                 ...                   ...                     ...   \n",
       "2765379               1               6.63125                    True   \n",
       "2765380               2               6.63125                    True   \n",
       "2765381               2               6.63125                    True   \n",
       "2765382               1               6.63125                    True   \n",
       "2765383               1               6.63125                    True   \n",
       "\n",
       "         Type local_Dépendance  \\\n",
       "0                        False   \n",
       "1                        False   \n",
       "2                        False   \n",
       "3                        False   \n",
       "4                        False   \n",
       "...                        ...   \n",
       "2765379                  False   \n",
       "2765380                  False   \n",
       "2765381                  False   \n",
       "2765382                  False   \n",
       "2765383                  False   \n",
       "\n",
       "         Type local_Local industriel. commercial ou assimilé  \\\n",
       "0                                                    False     \n",
       "1                                                    False     \n",
       "2                                                    False     \n",
       "3                                                    False     \n",
       "4                                                    False     \n",
       "...                                                    ...     \n",
       "2765379                                              False     \n",
       "2765380                                              False     \n",
       "2765381                                              False     \n",
       "2765382                                              False     \n",
       "2765383                                              False     \n",
       "\n",
       "         Type local_Maison  \n",
       "0                     True  \n",
       "1                     True  \n",
       "2                     True  \n",
       "3                     True  \n",
       "4                     True  \n",
       "...                    ...  \n",
       "2765379              False  \n",
       "2765380              False  \n",
       "2765381              False  \n",
       "2765382              False  \n",
       "2765383              False  \n",
       "\n",
       "[2765384 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables_explicatives = ['Type local', 'Nombre pieces principales', 'Surface reelle bati', 'Surface terrain',\n",
    "#                           'Nombre de lots', 'Code commune', 'Nature mutation']\n",
    "variables_explicatives = ['Type local', 'Nombre pieces principales', 'Surface reelle bati', \n",
    "                          'Surface terrain', 'Nombre de lots', 'Moyenne Taux Chomage']\n",
    "\n",
    "\n",
    "X = df[variables_explicatives]\n",
    "X = pd.get_dummies(data=X, columns=['Type local'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          204332.0\n",
       "1          226700.0\n",
       "2          185000.0\n",
       "3          114500.0\n",
       "4          145000.0\n",
       "             ...   \n",
       "2765379      1800.0\n",
       "2765380    405000.0\n",
       "2765381    220000.0\n",
       "2765382    383000.0\n",
       "2765383     45000.0\n",
       "Name: Valeur fonciere, Length: 2765384, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notre target\n",
    "Y = df['Valeur fonciere']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les NA dans la colonne 'Nombre pieces principales' et dans 'Surface reelle bati'\n",
    "# et dans 'Surface terrain' par leurs moyennes\n",
    "X['Nombre pieces principales'].fillna(X['Nombre pieces principales'].mean(), inplace=True)\n",
    "X['Surface reelle bati'].fillna(X['Surface reelle bati'].mean(), inplace=True)\n",
    "X['Surface terrain'].fillna(X['Surface terrain'].mean(), inplace=True)\n",
    "X['Nombre de lots'].fillna(X['Nombre de lots'].mean(), inplace=True)\n",
    "X['Moyenne Taux Chomage'].fillna(X['Moyenne Taux Chomage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nombre pieces principales                              0.0\n",
       "Surface reelle bati                                    0.0\n",
       "Surface terrain                                        0.0\n",
       "Nombre de lots                                         0.0\n",
       "Moyenne Taux Chomage                                   0.0\n",
       "Type local_Appartement                                 0.0\n",
       "Type local_Dépendance                                  0.0\n",
       "Type local_Local industriel. commercial ou assimilé    0.0\n",
       "Type local_Maison                                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_manquant = (X.isna().sum() / len(X)) * 100\n",
    "pourcentage_manquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#70% des données pour l’apprentissage\n",
    "#30% des données pour l'échantillon test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ne pas donner plus d'importance aux variables explicatives à forte variance, il est essentiel de centrer et réduire les données en amont. On centre et réduit également afin de les ramener à la même échelle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On centre et réduit les données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <th>Surface terrain</th>\n",
       "      <th>Nombre de lots</th>\n",
       "      <th>Moyenne Taux Chomage</th>\n",
       "      <th>Type local_Appartement</th>\n",
       "      <th>Type local_Dépendance</th>\n",
       "      <th>Type local_Local industriel. commercial ou assimilé</th>\n",
       "      <th>Type local_Maison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.449198</td>\n",
       "      <td>-0.120224</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.426909</td>\n",
       "      <td>-0.627619</td>\n",
       "      <td>1.645697</td>\n",
       "      <td>-0.403605</td>\n",
       "      <td>-0.229434</td>\n",
       "      <td>-1.084017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578410</td>\n",
       "      <td>0.085773</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>-0.695669</td>\n",
       "      <td>0.300481</td>\n",
       "      <td>-0.607645</td>\n",
       "      <td>-0.403605</td>\n",
       "      <td>-0.229434</td>\n",
       "      <td>0.922494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064606</td>\n",
       "      <td>0.240270</td>\n",
       "      <td>-0.119086</td>\n",
       "      <td>-0.695669</td>\n",
       "      <td>-0.518431</td>\n",
       "      <td>-0.607645</td>\n",
       "      <td>-0.403605</td>\n",
       "      <td>-0.229434</td>\n",
       "      <td>0.922494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nombre pieces principales  Surface reelle bati  Surface terrain  \\\n",
       "0                  -0.449198            -0.120224         0.000918   \n",
       "1                   0.578410             0.085773         0.194354   \n",
       "2                   0.064606             0.240270        -0.119086   \n",
       "\n",
       "   Nombre de lots  Moyenne Taux Chomage  Type local_Appartement  \\\n",
       "0        0.426909             -0.627619                1.645697   \n",
       "1       -0.695669              0.300481               -0.607645   \n",
       "2       -0.695669             -0.518431               -0.607645   \n",
       "\n",
       "   Type local_Dépendance  Type local_Local industriel. commercial ou assimilé  \\\n",
       "0              -0.403605                                          -0.229434     \n",
       "1              -0.403605                                          -0.229434     \n",
       "2              -0.403605                                          -0.229434     \n",
       "\n",
       "   Type local_Maison  \n",
       "0          -1.084017  \n",
       "1           0.922494  \n",
       "2           0.922494  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliquez la standardisation aux données de X\n",
    "scaler = StandardScaler()\n",
    "X_train_CR = scaler.fit_transform(X_train)\n",
    "X_test_CR = scaler.fit_transform(X_test)\n",
    "pd.DataFrame(X_train_CR, columns=X_test.columns).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression linéaire multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lance l'apprentissage du modèle sur l'échantillon d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483835     80000.0\n",
       "1211934    239100.0\n",
       "2529944    125000.0\n",
       "2760936     23000.0\n",
       "1712318    177800.0\n",
       "             ...   \n",
       "110268     100000.0\n",
       "1692743     81000.0\n",
       "2356330    107000.0\n",
       "2229084      8500.0\n",
       "2219110     55000.0\n",
       "Name: Valeur fonciere, Length: 1935768, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "model_LinearRegression = lm.fit(X_train_CR,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.87033067e+10,  2.87033295e+10,  2.87033304e+10, ...,\n",
       "       -2.76069744e+10,  2.87033533e+10, -2.76070289e+10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_LinearRegression.predict(X_test_CR)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60598593738.452576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on multiplie par 0.3 pour avoir un résultat en metre\n",
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'interesse aux coefficients de la régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <td>4.467470e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de lots</th>\n",
       "      <td>7.175250e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <td>3.514173e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface terrain</th>\n",
       "      <td>2.146642e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Appartement</th>\n",
       "      <td>5.904879e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Dépendance</th>\n",
       "      <td>4.616803e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Local industriel. commercial ou assimilé</th>\n",
       "      <td>2.896732e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Maison</th>\n",
       "      <td>6.629050e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constante</th>\n",
       "      <td>1.641013e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Coef\n",
       "Nombre pieces principales                           4.467470e+04\n",
       "Nombre de lots                                      7.175250e+03\n",
       "Surface reelle bati                                 3.514173e+03\n",
       "Surface terrain                                     2.146642e+03\n",
       "Type local_Appartement                              5.904879e+13\n",
       "Type local_Dépendance                               4.616803e+13\n",
       "Type local_Local industriel. commercial ou assi...  2.896732e+13\n",
       "Type local_Maison                                   6.629050e+13\n",
       "Constante                                           1.641013e+05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame(lm.coef_ ,index = X_train.columns, columns=['Coef'])\n",
    "coef.loc['Constante'] = lm.intercept_\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 100692.43715790247\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=10)\n",
    "ridge_model = ridge_model.fit(X_train_CR,y_train)\n",
    "\n",
    "y_pred = ridge_model.predict(X_test_CR)\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ,\n",
       "       6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ,\n",
       "       6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ,\n",
       "       6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5])},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha': np.arange(start = 0, stop = 10, step = 0.5)}\n",
    "\n",
    "ridge_model = Ridge()\n",
    "grid_ridge = GridSearchCV(ridge_model, parameters, scoring = 'neg_mean_squared_error')\n",
    "grid_ridge.fit(pd.DataFrame(X_train_CR, columns=X_train.columns), y_train)\n",
    "# grid_ridge.fit(X_train_CR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            params  mean_test_score\n",
      "0   {'alpha': 0.0}    -1.013721e+10\n",
      "1   {'alpha': 0.5}    -1.013721e+10\n",
      "2   {'alpha': 1.0}    -1.013721e+10\n",
      "3   {'alpha': 1.5}    -1.013721e+10\n",
      "4   {'alpha': 2.0}    -1.013721e+10\n",
      "5   {'alpha': 2.5}    -1.013721e+10\n",
      "6   {'alpha': 3.0}    -1.013721e+10\n",
      "7   {'alpha': 3.5}    -1.013721e+10\n",
      "8   {'alpha': 4.0}    -1.013721e+10\n",
      "9   {'alpha': 4.5}    -1.013721e+10\n",
      "10  {'alpha': 5.0}    -1.013721e+10\n",
      "11  {'alpha': 5.5}    -1.013721e+10\n",
      "12  {'alpha': 6.0}    -1.013721e+10\n",
      "13  {'alpha': 6.5}    -1.013721e+10\n",
      "14  {'alpha': 7.0}    -1.013721e+10\n",
      "15  {'alpha': 7.5}    -1.013721e+10\n",
      "16  {'alpha': 8.0}    -1.013721e+10\n",
      "17  {'alpha': 8.5}    -1.013721e+10\n",
      "18  {'alpha': 9.0}    -1.013721e+10\n",
      "19  {'alpha': 9.5}    -1.013721e+10\n",
      "Meilleur paramètre : {'alpha': 9.5}\n",
      "Meilleur score : -10137213138.263279\n",
      "RMSE : 100692.43711051517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid_ridge.cv_results_).loc[:,['params','mean_test_score']])\n",
    "print(\"Meilleur paramètre :\", grid_ridge.best_params_)\n",
    "print(\"Meilleur score :\", grid_ridge.best_score_)\n",
    "y_pred = grid_ridge.best_estimator_.predict(X_test_CR)\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <td>44685.529907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de lots</th>\n",
       "      <td>7259.775261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <td>3547.566840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface terrain</th>\n",
       "      <td>1939.908889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Appartement</th>\n",
       "      <td>-2941.588973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Dépendance</th>\n",
       "      <td>2948.759634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Local industriel. commercial ou assimilé</th>\n",
       "      <td>10912.957287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Maison</th>\n",
       "      <td>-4202.114504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constante</th>\n",
       "      <td>164101.304014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Coef\n",
       "Nombre pieces principales                            44685.529907\n",
       "Nombre de lots                                        7259.775261\n",
       "Surface reelle bati                                   3547.566840\n",
       "Surface terrain                                       1939.908889\n",
       "Type local_Appartement                               -2941.588973\n",
       "Type local_Dépendance                                 2948.759634\n",
       "Type local_Local industriel. commercial ou assi...   10912.957287\n",
       "Type local_Maison                                    -4202.114504\n",
       "Constante                                           164101.304014"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame(ridge_model.best_estimator_.coef_ ,\n",
    "                    index = X_train.columns, columns=['Coef'])\n",
    "coef.loc['Constante'] = ridge_model.best_estimator_.intercept_\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 100692.4351826682\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=5)\n",
    "lasso_model = lasso_model.fit(X_train_CR,y_train)\n",
    "\n",
    "y_pred = lasso_model.predict(X_test_CR)\n",
    "\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre pieces principales</th>\n",
       "      <td>44632.339240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de lots</th>\n",
       "      <td>7128.452419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface reelle bati</th>\n",
       "      <td>3518.184656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface terrain</th>\n",
       "      <td>2140.866760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Appartement</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Dépendance</th>\n",
       "      <td>5221.526143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Local industriel. commercial ou assimilé</th>\n",
       "      <td>12364.257885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type local_Maison</th>\n",
       "      <td>-641.661277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constante</th>\n",
       "      <td>164101.304014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Coef\n",
       "Nombre pieces principales                            44632.339240\n",
       "Nombre de lots                                        7128.452419\n",
       "Surface reelle bati                                   3518.184656\n",
       "Surface terrain                                       2140.866760\n",
       "Type local_Appartement                                  -0.000000\n",
       "Type local_Dépendance                                 5221.526143\n",
       "Type local_Local industriel. commercial ou assi...   12364.257885\n",
       "Type local_Maison                                     -641.661277\n",
       "Constante                                           164101.304014"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.DataFrame(lasso_model.coef_ ,\n",
    "                    index = X_train.columns, columns=['Coef'])\n",
    "coef.loc['Constante'] = lasso_model.intercept_\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est bon tu peux envoyer l'apprentissage !\n",
      "Nombre de combinaison :\n",
      "10\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+15, tolerance: 1.798e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e+15, tolerance: 1.801e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.860e+15, tolerance: 1.800e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=0; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': np.arange(start = 0, stop = 10, step = 1)}\n",
    "print(alerteCombinaison(parameters))\n",
    "lasso_model = Lasso()\n",
    "lasso_model = GridSearchCV(lasso_model, parameters, scoring = 'r2', verbose = 2)\n",
    "lasso_model.fit(X_train_CR, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso était beaucoup trop long, et faisait même planter mon PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 104905.91176840823\n"
     ]
    }
   ],
   "source": [
    "elastic_model = ElasticNet(alpha=5, l1_ratio=0.2)\n",
    "elastic_model = elastic_model.fit(X_train_CR,y_train)\n",
    "\n",
    "y_pred = elastic_model.predict(X_test_CR)\n",
    "\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.239e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.253e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.340e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.354e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.396e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.433e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.446e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.459e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.471e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.478e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.493e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.505e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.517e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.515e+15, tolerance: 1.123e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.527e+15, tolerance: 1.125e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.811e+15, tolerance: 2.248e+12 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.2, 0.4, 0.6, 0.8])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.2, 0.4, 0.6, 0.8])},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'l1_ratio': array([0. , 0.2, 0.4, 0.6, 0.8])},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha' : np.arange(0,10,1),\n",
    "             'l1_ratio' : np.arange(0,1,0.2)}\n",
    "\n",
    "elastic_model = ElasticNet()\n",
    "grid_elasticnet = GridSearchCV(elastic_model, parameters, scoring = 'neg_mean_squared_error', verbose=1, cv=2)\n",
    "grid_elasticnet.fit(pd.DataFrame(X_train_CR, columns=X_train.columns), y_train)\n",
    "# grid_ridge.fit(X_train_CR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          params  mean_test_score\n",
      "0                  {'alpha': 0, 'l1_ratio': 0.0}    -1.013666e+10\n",
      "1                  {'alpha': 0, 'l1_ratio': 0.2}    -1.013666e+10\n",
      "2                  {'alpha': 0, 'l1_ratio': 0.4}    -1.013666e+10\n",
      "3   {'alpha': 0, 'l1_ratio': 0.6000000000000001}    -1.013666e+10\n",
      "4                  {'alpha': 0, 'l1_ratio': 0.8}    -1.013666e+10\n",
      "5                  {'alpha': 1, 'l1_ratio': 0.0}    -1.054198e+10\n",
      "6                  {'alpha': 1, 'l1_ratio': 0.2}    -1.048324e+10\n",
      "7                  {'alpha': 1, 'l1_ratio': 0.4}    -1.041489e+10\n",
      "8   {'alpha': 1, 'l1_ratio': 0.6000000000000001}    -1.033274e+10\n",
      "9                  {'alpha': 1, 'l1_ratio': 0.8}    -1.023094e+10\n",
      "10                 {'alpha': 2, 'l1_ratio': 0.0}    -1.075370e+10\n",
      "11                 {'alpha': 2, 'l1_ratio': 0.2}    -1.068124e+10\n",
      "12                 {'alpha': 2, 'l1_ratio': 0.4}    -1.059362e+10\n",
      "13  {'alpha': 2, 'l1_ratio': 0.6000000000000001}    -1.048328e+10\n",
      "14                 {'alpha': 2, 'l1_ratio': 0.8}    -1.033277e+10\n",
      "15                 {'alpha': 3, 'l1_ratio': 0.0}    -1.089182e+10\n",
      "16                 {'alpha': 3, 'l1_ratio': 0.2}    -1.081512e+10\n",
      "17                 {'alpha': 3, 'l1_ratio': 0.4}    -1.071909e+10\n",
      "18  {'alpha': 3, 'l1_ratio': 0.6000000000000001}    -1.059365e+10\n",
      "19                 {'alpha': 3, 'l1_ratio': 0.8}    -1.041495e+10\n",
      "20                 {'alpha': 4, 'l1_ratio': 0.0}    -1.099089e+10\n",
      "21                 {'alpha': 4, 'l1_ratio': 0.2}    -1.091416e+10\n",
      "22                 {'alpha': 4, 'l1_ratio': 0.4}    -1.081515e+10\n",
      "23  {'alpha': 4, 'l1_ratio': 0.6000000000000001}    -1.068130e+10\n",
      "24                 {'alpha': 4, 'l1_ratio': 0.8}    -1.048334e+10\n",
      "25                 {'alpha': 5, 'l1_ratio': 0.0}    -1.106577e+10\n",
      "26                 {'alpha': 5, 'l1_ratio': 0.2}    -1.099092e+10\n",
      "27                 {'alpha': 5, 'l1_ratio': 0.4}    -1.089187e+10\n",
      "28  {'alpha': 5, 'l1_ratio': 0.6000000000000001}    -1.075379e+10\n",
      "29                 {'alpha': 5, 'l1_ratio': 0.8}    -1.054211e+10\n",
      "30                 {'alpha': 6, 'l1_ratio': 0.0}    -1.112444e+10\n",
      "31                 {'alpha': 6, 'l1_ratio': 0.2}    -1.105231e+10\n",
      "32                 {'alpha': 6, 'l1_ratio': 0.4}    -1.095484e+10\n",
      "33  {'alpha': 6, 'l1_ratio': 0.6000000000000001}    -1.081520e+10\n",
      "34                 {'alpha': 6, 'l1_ratio': 0.8}    -1.059374e+10\n",
      "35                 {'alpha': 7, 'l1_ratio': 0.0}    -1.117169e+10\n",
      "36                 {'alpha': 7, 'l1_ratio': 0.2}    -1.110259e+10\n",
      "37                 {'alpha': 7, 'l1_ratio': 0.4}    -1.100754e+10\n",
      "38  {'alpha': 7, 'l1_ratio': 0.6000000000000001}    -1.086810e+10\n",
      "39                 {'alpha': 7, 'l1_ratio': 0.8}    -1.063983e+10\n",
      "40                 {'alpha': 8, 'l1_ratio': 0.0}    -1.121057e+10\n",
      "41                 {'alpha': 8, 'l1_ratio': 0.2}    -1.114454e+10\n",
      "42                 {'alpha': 8, 'l1_ratio': 0.4}    -1.105235e+10\n",
      "43  {'alpha': 8, 'l1_ratio': 0.6000000000000001}    -1.091425e+10\n",
      "44                 {'alpha': 8, 'l1_ratio': 0.8}    -1.068142e+10\n",
      "45                 {'alpha': 9, 'l1_ratio': 0.0}    -1.124313e+10\n",
      "46                 {'alpha': 9, 'l1_ratio': 0.2}    -1.118009e+10\n",
      "47                 {'alpha': 9, 'l1_ratio': 0.4}    -1.109093e+10\n",
      "48  {'alpha': 9, 'l1_ratio': 0.6000000000000001}    -1.095491e+10\n",
      "49                 {'alpha': 9, 'l1_ratio': 0.8}    -1.071927e+10\n",
      "Meilleur paramètre : {'alpha': 0, 'l1_ratio': 0.0}\n",
      "Meilleur score : -10136660299.117317\n",
      "RMSE : 100692.43271360296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid_elasticnet.cv_results_).loc[:,['params','mean_test_score']])\n",
    "print(\"Meilleur paramètre :\", grid_elasticnet.best_params_)\n",
    "print(\"Meilleur score :\", grid_elasticnet.best_score_)\n",
    "y_pred = grid_elasticnet.best_estimator_.predict(X_test_CR)\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 12777387809.924845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "tree_regressor.fit(X_train_CR, y_train)\n",
    "y_pred = tree_regressor.predict(X_test_CR)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Affichez le MSE pour évaluer la performance du modèle\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_regressor = DecisionTreeRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],  # Profondeur maximale de l'arbre\n",
    "    'min_samples_split': [2, 5, 10],  # Nombre minimal d'échantillons requis pour diviser un nœud\n",
    "    'min_samples_leaf': [1, 2, 4]  # Nombre minimal d'échantillons requis dans une feuille\n",
    "}\n",
    "grid_tree_regressor = GridSearchCV(tree_regressor, param_grid=param_grid, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "grid_tree_regressor.fit(pd.DataFrame(X_train_CR, columns=X_train.columns), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur paramètre : {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Meilleur score : -6680644535.062864\n",
      "RMSE : 84197.18561422486\n"
     ]
    }
   ],
   "source": [
    "# print(pd.DataFrame(tree_regressor.cv_results_).loc[:,['params','mean_test_score']])\n",
    "print(\"Meilleur paramètre :\", grid_tree_regressor.best_params_)\n",
    "print(\"Meilleur score :\", grid_tree_regressor.best_score_)\n",
    "\n",
    "y_pred = grid_tree_regressor.predict(pd.DataFrame(X_test_CR, columns=X_test.columns))\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_test_score\n",
      "0   {'max_depth': None, 'min_samples_leaf': 1, 'mi...        -0.054894\n",
      "1   {'max_depth': None, 'min_samples_leaf': 1, 'mi...        -0.009273\n",
      "2   {'max_depth': None, 'min_samples_leaf': 1, 'mi...         0.046871\n",
      "3   {'max_depth': None, 'min_samples_leaf': 2, 'mi...         0.022037\n",
      "4   {'max_depth': None, 'min_samples_leaf': 2, 'mi...         0.028152\n",
      "5   {'max_depth': None, 'min_samples_leaf': 2, 'mi...         0.064082\n",
      "6   {'max_depth': None, 'min_samples_leaf': 4, 'mi...         0.083782\n",
      "7   {'max_depth': None, 'min_samples_leaf': 4, 'mi...         0.083764\n",
      "8   {'max_depth': None, 'min_samples_leaf': 4, 'mi...         0.088451\n",
      "9   {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.187218\n",
      "10  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.187263\n",
      "11  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.187304\n",
      "12  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...         0.187289\n",
      "13  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...         0.187296\n",
      "14  {'max_depth': 10, 'min_samples_leaf': 2, 'min_...         0.187336\n",
      "15  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...         0.187442\n",
      "16  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...         0.187442\n",
      "17  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...         0.187456\n",
      "18  {'max_depth': 20, 'min_samples_leaf': 1, 'min_...         0.129547\n",
      "19  {'max_depth': 20, 'min_samples_leaf': 1, 'min_...         0.136366\n",
      "20  {'max_depth': 20, 'min_samples_leaf': 1, 'min_...         0.145345\n",
      "21  {'max_depth': 20, 'min_samples_leaf': 2, 'min_...         0.140284\n",
      "22  {'max_depth': 20, 'min_samples_leaf': 2, 'min_...         0.141347\n",
      "23  {'max_depth': 20, 'min_samples_leaf': 2, 'min_...         0.148303\n",
      "24  {'max_depth': 20, 'min_samples_leaf': 4, 'min_...         0.151070\n",
      "25  {'max_depth': 20, 'min_samples_leaf': 4, 'min_...         0.151062\n",
      "26  {'max_depth': 20, 'min_samples_leaf': 4, 'min_...         0.152268\n",
      "27  {'max_depth': 30, 'min_samples_leaf': 1, 'min_...        -0.004666\n",
      "28  {'max_depth': 30, 'min_samples_leaf': 1, 'min_...         0.027449\n",
      "29  {'max_depth': 30, 'min_samples_leaf': 1, 'min_...         0.068743\n",
      "30  {'max_depth': 30, 'min_samples_leaf': 2, 'min_...         0.048636\n",
      "31  {'max_depth': 30, 'min_samples_leaf': 2, 'min_...         0.053206\n",
      "32  {'max_depth': 30, 'min_samples_leaf': 2, 'min_...         0.080834\n",
      "33  {'max_depth': 30, 'min_samples_leaf': 4, 'min_...         0.094922\n",
      "34  {'max_depth': 30, 'min_samples_leaf': 4, 'min_...         0.094928\n",
      "35  {'max_depth': 30, 'min_samples_leaf': 4, 'min_...         0.098738\n",
      "Meilleur paramètre : {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Meilleur score : 0.1874560876831884\n",
      "RMSE : 102543.816240923\n"
     ]
    }
   ],
   "source": [
    "random_forest_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest_regressor.fit(X_train, y_train)\n",
    "y_pred = random_forest_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bourh\\Cours\\CoursM2SISE\\Machine_Learning_Python\\ProjetPython\\modeles-ml-dounya.ipynb Cell 54\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bourh/Cours/CoursM2SISE/Machine_Learning_Python/ProjetPython/modeles-ml-dounya.ipynb#Y131sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m random_forest_regressor \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bourh/Cours/CoursM2SISE/Machine_Learning_Python/ProjetPython/modeles-ml-dounya.ipynb#Y131sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m grid_random_forest \u001b[39m=\u001b[39m GridSearchCV(random_forest_regressor, param_grid\u001b[39m=\u001b[39mparam_grid, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bourh/Cours/CoursM2SISE/Machine_Learning_Python/ProjetPython/modeles-ml-dounya.ipynb#Y131sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid_random_forest\u001b[39m.\u001b[39;49mfit(pd\u001b[39m.\u001b[39;49mDataFrame(X_train_CR, columns\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mcolumns), y_train)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bourh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "random_forest_regressor = RandomForestRegressor()\n",
    "grid_random_forest = GridSearchCV(random_forest_regressor, param_grid=param_grid, scoring=\"neg_mean_squared_error\")\n",
    "grid_random_forest.fit(pd.DataFrame(X_train_CR, columns=X_train.columns), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle a tourné pendant plus de 2h sans résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(tree_regressor.cv_results_).loc[:,['params','mean_test_score']])\n",
    "print(\"Meilleur paramètre :\", grid_random_forest.best_params_)\n",
    "print(\"Meilleur score :\", grid_random_forest.best_score_)\n",
    "\n",
    "y_pred = grid_random_forest.predict(pd.DataFrame(X_test_CR, columns=X_test.columns))\n",
    "print(\"RMSE : \" + str(mean_squared_error(y_test, y_pred, squared= False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                        title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "---------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "iamsouravbanerjee/customer-shopping-trends-dataset         Customer Shopping Trends Dataset                  146KB  2023-10-05 06:45:37           4688        116  1.0              \n",
      "nelgiriyewithana/top-spotify-songs-2023                    Most Streamed Spotify Songs 2023                   47KB  2023-08-26 11:04:57          31838        961  1.0              \n",
      "nelgiriyewithana/credit-card-fraud-detection-dataset-2023  Credit Card Fraud Detection Dataset 2023          143MB  2023-09-18 10:00:19           5456        185  1.0              \n",
      "nelgiriyewithana/billionaires-statistics-dataset           Billionaires Statistics Dataset (2023)            139KB  2023-09-29 13:39:28           3003         97  1.0              \n",
      "asaniczka/wages-by-education-in-the-usa-1973-2022          Wages by Education in the USA (1973-2022)           7KB  2023-10-09 09:43:40           1075         29  1.0              \n",
      "zedataweaver/global-salary-data                            Global Salary Data                                  5KB  2023-10-03 00:55:24           1736         47  1.0              \n",
      "qnqfbqfqo/electric-vehicle-population-in-washington-state  Electric Vehicle Population in Washington State     5MB  2023-10-10 06:44:26            539         24  1.0              \n",
      "willianoliveiragibin/10000-data-about-movies-1915-2023     10,000 Data  about movies (1915 - 2023)             1MB  2023-10-11 19:31:12            738         24  1.0              \n",
      "yakhyojon/air-quality-data                                 Air Quality Data                                    7KB  2023-10-12 07:45:04            645         26  1.0              \n",
      "anshtanwar/monthly-food-price-estimates                    Monthly Food Price Inflation                       44MB  2023-10-08 05:22:42           1639         40  1.0              \n",
      "sujaykapadnis/fast-food-calories-data                      Fast Food Calories Data                            13KB  2023-10-13 04:48:07            528         24  1.0              \n",
      "nyagami/fc-24-players-database-and-stats-from-easports     EA SPORTS FC 24 FULL PLAYERS DATABASE AND STATS     3MB  2023-10-09 22:43:27            518         27  1.0              \n",
      "alexhuitron/supermarket-sales                              Supermarket Sales                                  36KB  2023-10-02 20:42:03           1166         26  0.88235295       \n",
      "gabrielsantello/wholesale-and-retail-orders-dataset        Wholesale & Retail Orders Dataset                   3MB  2023-09-19 09:31:40            837         27  1.0              \n",
      "yakhyojon/customer-satisfaction-in-airline                 Customer Satisfaction in Airline                    2MB  2023-10-12 09:35:07            657         29  1.0              \n",
      "iamsouravbanerjee/heart-attack-prediction-dataset          Heart Attack Risk Prediction Dataset              519KB  2023-09-27 07:07:50           2736         58  1.0              \n",
      "zsinghrahulk/israel-vs-palestine                           Israel vs Palestine                                 2KB  2023-10-09 10:06:18            337         23  1.0              \n",
      "talhabarkaatahmad/laptop-prices-dataset-october-2023       Laptop Prices Dataset - October 2023               63KB  2023-10-09 13:34:58           1150         27  1.0              \n",
      "tawfikelmetwally/employee-dataset                          Employee dataset                                   19KB  2023-09-06 18:15:55           8388        143  0.9411765        \n",
      "joebeachcapital/students-performance                       Students Performance                                2KB  2023-08-31 00:50:11          10901        238  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading m2-sise-2023.zip to c:\\Users\\bourh\\Cours\\CoursM2SISE\\Machine_Learning_Python\\ProjetPython\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/295M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/295M [00:00<03:25, 1.50MB/s]\n",
      "  1%|          | 3.00M/295M [00:00<01:05, 4.69MB/s]\n",
      "  2%|▏         | 6.00M/295M [00:00<00:32, 9.33MB/s]\n",
      "  3%|▎         | 10.0M/295M [00:01<00:19, 15.7MB/s]\n",
      "  5%|▍         | 14.0M/295M [00:01<00:15, 19.0MB/s]\n",
      "  6%|▌         | 18.0M/295M [00:01<00:12, 23.7MB/s]\n",
      "  7%|▋         | 21.0M/295M [00:01<00:12, 22.8MB/s]\n",
      "  8%|▊         | 24.0M/295M [00:01<00:11, 24.5MB/s]\n",
      "  9%|▉         | 27.0M/295M [00:01<00:12, 22.0MB/s]\n",
      " 11%|█         | 31.0M/295M [00:01<00:13, 20.6MB/s]\n",
      " 12%|█▏        | 35.0M/295M [00:02<00:11, 24.1MB/s]\n",
      " 13%|█▎        | 38.0M/295M [00:02<00:12, 21.4MB/s]\n",
      " 14%|█▍        | 41.0M/295M [00:02<00:16, 16.2MB/s]\n",
      " 15%|█▍        | 43.0M/295M [00:02<00:21, 12.6MB/s]\n",
      " 15%|█▌        | 45.0M/295M [00:03<00:23, 11.0MB/s]\n",
      " 17%|█▋        | 49.0M/295M [00:03<00:16, 15.5MB/s]\n",
      " 18%|█▊        | 52.0M/295M [00:03<00:15, 16.5MB/s]\n",
      " 19%|█▊        | 55.0M/295M [00:03<00:13, 19.0MB/s]\n",
      " 20%|█▉        | 59.0M/295M [00:03<00:10, 22.5MB/s]\n",
      " 21%|██        | 62.0M/295M [00:04<00:20, 12.2MB/s]\n",
      " 22%|██▏       | 66.0M/295M [00:04<00:20, 11.7MB/s]\n",
      " 24%|██▎       | 70.0M/295M [00:04<00:15, 15.3MB/s]\n",
      " 25%|██▌       | 74.0M/295M [00:04<00:12, 19.0MB/s]\n",
      " 26%|██▌       | 77.0M/295M [00:04<00:11, 20.3MB/s]\n",
      " 27%|██▋       | 81.0M/295M [00:05<00:09, 23.0MB/s]\n",
      " 29%|██▉       | 86.0M/295M [00:05<00:07, 28.4MB/s]\n",
      " 30%|███       | 90.0M/295M [00:05<00:07, 27.9MB/s]\n",
      " 32%|███▏      | 95.0M/295M [00:05<00:06, 32.9MB/s]\n",
      " 34%|███▎      | 99.0M/295M [00:05<00:07, 27.9MB/s]\n",
      " 35%|███▍      | 103M/295M [00:05<00:09, 22.3MB/s] \n",
      " 36%|███▌      | 106M/295M [00:06<00:10, 19.4MB/s]\n",
      " 37%|███▋      | 110M/295M [00:06<00:08, 21.7MB/s]\n",
      " 38%|███▊      | 113M/295M [00:06<00:08, 23.0MB/s]\n",
      " 40%|███▉      | 117M/295M [00:06<00:07, 26.6MB/s]\n",
      " 41%|████      | 120M/295M [00:06<00:08, 22.1MB/s]\n",
      " 42%|████▏     | 124M/295M [00:06<00:06, 25.8MB/s]\n",
      " 43%|████▎     | 128M/295M [00:06<00:06, 28.9MB/s]\n",
      " 45%|████▍     | 132M/295M [00:07<00:07, 21.8MB/s]\n",
      " 46%|████▌     | 136M/295M [00:07<00:06, 25.2MB/s]\n",
      " 47%|████▋     | 139M/295M [00:07<00:06, 24.8MB/s]\n",
      " 48%|████▊     | 143M/295M [00:07<00:05, 28.0MB/s]\n",
      " 49%|████▉     | 146M/295M [00:07<00:05, 26.9MB/s]\n",
      " 50%|█████     | 149M/295M [00:07<00:06, 25.2MB/s]\n",
      " 52%|█████▏    | 153M/295M [00:08<00:06, 22.9MB/s]\n",
      " 53%|█████▎    | 156M/295M [00:08<00:08, 16.7MB/s]\n",
      " 54%|█████▍    | 160M/295M [00:08<00:06, 20.7MB/s]\n",
      " 55%|█████▌    | 163M/295M [00:08<00:06, 22.4MB/s]\n",
      " 56%|█████▌    | 166M/295M [00:08<00:05, 24.2MB/s]\n",
      " 57%|█████▋    | 169M/295M [00:08<00:05, 24.6MB/s]\n",
      " 58%|█████▊    | 172M/295M [00:09<00:05, 24.5MB/s]\n",
      " 60%|█████▉    | 176M/295M [00:09<00:04, 28.1MB/s]\n",
      " 61%|██████    | 179M/295M [00:09<00:05, 22.6MB/s]\n",
      " 62%|██████▏   | 182M/295M [00:09<00:04, 24.4MB/s]\n",
      " 63%|██████▎   | 185M/295M [00:09<00:05, 20.7MB/s]\n",
      " 64%|██████▍   | 189M/295M [00:09<00:04, 24.8MB/s]\n",
      " 65%|██████▌   | 193M/295M [00:10<00:05, 20.4MB/s]\n",
      " 67%|██████▋   | 197M/295M [00:10<00:04, 24.1MB/s]\n",
      " 68%|██████▊   | 201M/295M [00:10<00:06, 15.3MB/s]\n",
      " 69%|██████▉   | 205M/295M [00:10<00:05, 18.5MB/s]\n",
      " 71%|███████   | 209M/295M [00:10<00:04, 18.1MB/s]\n",
      " 72%|███████▏  | 213M/295M [00:11<00:03, 21.6MB/s]\n",
      " 74%|███████▎  | 217M/295M [00:11<00:03, 21.8MB/s]\n",
      " 75%|███████▍  | 221M/295M [00:11<00:03, 25.2MB/s]\n",
      " 76%|███████▌  | 225M/295M [00:11<00:02, 28.1MB/s]\n",
      " 78%|███████▊  | 229M/295M [00:11<00:02, 29.1MB/s]\n",
      " 79%|███████▉  | 234M/295M [00:11<00:01, 34.3MB/s]\n",
      " 81%|████████  | 238M/295M [00:11<00:01, 33.0MB/s]\n",
      " 82%|████████▏ | 242M/295M [00:12<00:01, 33.4MB/s]\n",
      " 83%|████████▎ | 246M/295M [00:12<00:01, 27.9MB/s]\n",
      " 84%|████████▍ | 249M/295M [00:12<00:01, 24.8MB/s]\n",
      " 86%|████████▌ | 253M/295M [00:12<00:01, 24.8MB/s]\n",
      " 87%|████████▋ | 257M/295M [00:12<00:01, 21.1MB/s]\n",
      " 88%|████████▊ | 261M/295M [00:12<00:01, 24.7MB/s]\n",
      " 90%|████████▉ | 265M/295M [00:13<00:01, 27.4MB/s]\n",
      " 91%|█████████ | 269M/295M [00:13<00:00, 30.1MB/s]\n",
      " 92%|█████████▏| 273M/295M [00:13<00:00, 32.3MB/s]\n",
      " 94%|█████████▍| 277M/295M [00:13<00:00, 34.0MB/s]\n",
      " 95%|█████████▌| 281M/295M [00:13<00:00, 34.5MB/s]\n",
      " 97%|█████████▋| 285M/295M [00:13<00:00, 23.8MB/s]\n",
      " 98%|█████████▊| 289M/295M [00:13<00:00, 26.6MB/s]\n",
      " 99%|█████████▉| 293M/295M [00:14<00:00, 29.2MB/s]\n",
      "100%|██████████| 295M/295M [00:14<00:00, 22.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c m2-sise-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"./content/m2-sise-2023.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./content\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
